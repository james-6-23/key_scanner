#!/usr/bin/env python3
"""
è¯Šæ–­å·¥å…· - æ£€æŸ¥Tokené…ç½®å’Œæ•°æ®æ–‡ä»¶çŠ¶æ€
å¸®åŠ©è§£å†³ï¼š
1. Tokenæ•°é‡ä¸ä¸€è‡´é—®é¢˜
2. æ•°æ®æ–‡ä»¶æœªç”Ÿæˆé—®é¢˜
"""

import os
import sys
import json
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from common.Logger import logger
from common.config import Config


def check_token_files():
    """æ£€æŸ¥Tokené…ç½®æ–‡ä»¶"""
    print("\n" + "="*60)
    print("ğŸ” TOKEN CONFIGURATION CHECK")
    print("="*60)
    
    # 1. æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„Token
    env_tokens = os.getenv('GITHUB_TOKENS', '')
    env_token_count = 0
    if env_tokens:
        env_token_list = [t.strip() for t in env_tokens.split(',') if t.strip()]
        env_token_count = len(env_token_list)
        print(f"âœ… Environment variable GITHUB_TOKENS: {env_token_count} tokens found")
    else:
        print("âŒ Environment variable GITHUB_TOKENS: Not set or empty")
    
    # 2. æ£€æŸ¥github_tokens.txtæ–‡ä»¶
    tokens_file = "github_tokens.txt"
    file_token_count = 0
    file_tokens = []
    
    if os.path.exists(tokens_file):
        with open(tokens_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            for line in lines:
                line = line.strip()
                if line and not line.startswith('#'):
                    file_tokens.append(line)
            file_token_count = len(file_tokens)
        print(f"âœ… File {tokens_file}: {file_token_count} tokens found")
        
        # éªŒè¯tokenæ ¼å¼
        valid_tokens = 0
        for token in file_tokens:
            if token.startswith('ghp_') or token.startswith('github_pat_') or len(token) == 40:
                valid_tokens += 1
            else:
                print(f"   âš ï¸ Invalid token format: {token[:10]}...")
        
        if valid_tokens != file_token_count:
            print(f"   âš ï¸ Only {valid_tokens}/{file_token_count} tokens have valid format")
    else:
        print(f"âŒ File {tokens_file}: Not found")
        print(f"   ğŸ’¡ Create {tokens_file} and add your GitHub tokens (one per line)")
    
    # 3. æ£€æŸ¥.envæ–‡ä»¶
    env_file = ".env"
    if os.path.exists(env_file):
        print(f"âœ… File {env_file}: Found")
        with open(env_file, 'r') as f:
            content = f.read()
            if 'GITHUB_TOKENS=' in content:
                print(f"   âœ… GITHUB_TOKENS variable defined in .env")
            else:
                print(f"   âŒ GITHUB_TOKENS variable not found in .env")
    else:
        print(f"âš ï¸ File {env_file}: Not found (optional)")
    
    # 4. æ£€æŸ¥é…ç½®ä¸­çš„Tokenæ¨¡å¼
    print(f"\nğŸ“‹ Configuration:")
    print(f"   USE_EXTERNAL_TOKEN_FILE: {Config.USE_EXTERNAL_TOKEN_FILE}")
    print(f"   GITHUB_TOKENS_FILE: {Config.GITHUB_TOKENS_FILE}")
    
    # 5. å»ºè®®
    print(f"\nğŸ’¡ Recommendations:")
    if Config.USE_EXTERNAL_TOKEN_FILE:
        print(f"   You are using external file mode")
        print(f"   Make sure {Config.GITHUB_TOKENS_FILE} exists and contains valid tokens")
    else:
        print(f"   You are using environment variable mode")
        print(f"   Make sure GITHUB_TOKENS is set in .env or environment")
    
    return {
        'env_tokens': env_token_count,
        'file_tokens': file_token_count,
        'mode': 'file' if Config.USE_EXTERNAL_TOKEN_FILE else 'env'
    }


def check_data_files():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶çŠ¶æ€"""
    print("\n" + "="*60)
    print("ğŸ“ DATA FILES CHECK")
    print("="*60)
    
    data_dir = Config.DATA_PATH
    print(f"Data directory: {data_dir}")
    
    if not os.path.exists(data_dir):
        print(f"âŒ Data directory does not exist!")
        return
    
    # æ£€æŸ¥ä»Šå¤©çš„æ•°æ®æ–‡ä»¶
    today = datetime.now().strftime('%Y%m%d')
    
    files_to_check = [
        (f"keys_valid_{today}.txt", "Valid keys"),
        (f"rate_limited_{today}.txt", "Rate limited keys"),
        (f"keys_valid_detail_{today}.log", "Valid keys details"),
        (f"rate_limited_detail_{today}.log", "Rate limited details"),
        ("checkpoint.json", "Checkpoint"),
        ("scanned_shas.txt", "Scanned SHAs")
    ]
    
    found_files = []
    for filename, description in files_to_check:
        filepath = os.path.join(data_dir, filename)
        if os.path.exists(filepath):
            size = os.path.getsize(filepath)
            found_files.append(filepath)
            
            # è¯»å–æ–‡ä»¶å†…å®¹ç»Ÿè®¡
            if filename.endswith('.txt') and 'keys_valid' in filename:
                with open(filepath, 'r') as f:
                    lines = f.readlines()
                    key_count = len([l for l in lines if l.strip()])
                print(f"âœ… {description}: {filename} ({size} bytes, {key_count} keys)")
            elif filename == 'checkpoint.json':
                with open(filepath, 'r') as f:
                    checkpoint = json.load(f)
                    queries = len(checkpoint.get('processed_queries', []))
                    last_scan = checkpoint.get('last_scan_time', 'Never')
                print(f"âœ… {description}: {filename} ({size} bytes)")
                print(f"   Last scan: {last_scan}")
                print(f"   Processed queries: {queries}")
            elif filename == 'scanned_shas.txt':
                with open(filepath, 'r') as f:
                    lines = f.readlines()
                    sha_count = len([l for l in lines if l.strip() and not l.startswith('#')])
                print(f"âœ… {description}: {filename} ({size} bytes, {sha_count} SHAs)")
            else:
                print(f"âœ… {description}: {filename} ({size} bytes)")
        else:
            print(f"âŒ {description}: {filename} (not found)")
    
    # æ£€æŸ¥å†å²æ•°æ®æ–‡ä»¶
    print(f"\nğŸ“… Historical data files:")
    all_valid_keys = []
    all_rate_limited = []
    
    for file in os.listdir(data_dir):
        if file.startswith('keys_valid_') and file.endswith('.txt'):
            filepath = os.path.join(data_dir, file)
            with open(filepath, 'r') as f:
                keys = [l.strip() for l in f.readlines() if l.strip()]
                all_valid_keys.extend(keys)
                if keys:
                    print(f"   {file}: {len(keys)} keys")
        elif file.startswith('rate_limited_') and file.endswith('.txt'):
            filepath = os.path.join(data_dir, file)
            with open(filepath, 'r') as f:
                keys = [l.strip() for l in f.readlines() if l.strip()]
                all_rate_limited.extend(keys)
    
    print(f"\nğŸ“Š Summary:")
    print(f"   Total valid keys found (all time): {len(set(all_valid_keys))}")
    print(f"   Total rate limited keys (all time): {len(set(all_rate_limited))}")
    
    return found_files


def check_queries_file():
    """æ£€æŸ¥æŸ¥è¯¢æ–‡ä»¶"""
    print("\n" + "="*60)
    print("ğŸ” QUERIES FILE CHECK")
    print("="*60)
    
    queries_file = Config.QUERIES_FILE
    print(f"Queries file: {queries_file}")
    
    if os.path.exists(queries_file):
        with open(queries_file, 'r') as f:
            lines = f.readlines()
            queries = [l.strip() for l in lines if l.strip() and not l.startswith('#')]
        print(f"âœ… Found {len(queries)} queries")
        
        # æ˜¾ç¤ºå‰5ä¸ªæŸ¥è¯¢
        print(f"\n   First few queries:")
        for i, q in enumerate(queries[:5], 1):
            print(f"   {i}. {q[:50]}..." if len(q) > 50 else f"   {i}. {q}")
    else:
        print(f"âŒ Queries file not found!")
        print(f"   ğŸ’¡ Copy queries.example to {queries_file} to get started")
        
        # æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶
        if os.path.exists("queries.example"):
            print(f"   âœ… queries.example found - you can use it as template")
        else:
            print(f"   âŒ queries.example also not found")


def test_token_manager():
    """æµ‹è¯•Tokenç®¡ç†å™¨"""
    print("\n" + "="*60)
    print("ğŸ§ª TOKEN MANAGER TEST")
    print("="*60)
    
    try:
        from utils.github_client import GitHubClient
        
        # åˆ›å»ºGitHubå®¢æˆ·ç«¯å®ä¾‹
        github_client = GitHubClient.create_instance(use_token_manager=True)
        
        # è·å–TokençŠ¶æ€
        status = github_client.get_token_status()
        
        print(f"âœ… Token Manager initialized successfully")
        print(f"   Total tokens: {status.get('total_tokens', 0)}")
        print(f"   Active tokens: {status.get('active_tokens', 0)}")
        print(f"   Total remaining calls: {status.get('total_remaining_calls', 'N/A')}")
        
        # æ˜¾ç¤ºæ¯ä¸ªtokençš„çŠ¶æ€
        if 'tokens' in status:
            print(f"\n   Token details:")
            for token_info in status['tokens']:
                print(f"   - {token_info['token']}: {token_info['remaining']} calls remaining")
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to initialize Token Manager: {e}")
        import traceback
        traceback.print_exc()
        return False


def suggest_fixes():
    """æä¾›ä¿®å¤å»ºè®®"""
    print("\n" + "="*60)
    print("ğŸ’¡ TROUBLESHOOTING GUIDE")
    print("="*60)
    
    print("""
1. å¦‚æœTokenæ•°é‡ä¸ä¸€è‡´ï¼š
   - ç¡®ä¿æ‰€æœ‰å·¥å…·ä½¿ç”¨ç›¸åŒçš„Tokenæº
   - å¦‚æœä½¿ç”¨æ–‡ä»¶æ¨¡å¼ï¼Œæ£€æŸ¥ github_tokens.txt
   - å¦‚æœä½¿ç”¨ç¯å¢ƒå˜é‡æ¨¡å¼ï¼Œæ£€æŸ¥ .env æ–‡ä»¶ä¸­çš„ GITHUB_TOKENS
   
2. å¦‚æœæ•°æ®æ–‡ä»¶æœªç”Ÿæˆï¼š
   - ä½¿ç”¨æ”¹è¿›ç‰ˆæ‰«æå™¨: python app/api_key_scanner_improved.py
   - ç¡®ä¿æœ‰å†™å…¥æƒé™åˆ° data/ ç›®å½•
   - æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æŸ¥è¯¢åœ¨ queries.txt
   
3. å¦‚æœç¨‹åºä¸­æ–­å¯¼è‡´æ•°æ®ä¸¢å¤±ï¼š
   - æ”¹è¿›ç‰ˆä¼šå®æ—¶ä¿å­˜æ•°æ®
   - ä½¿ç”¨ Ctrl+C ä¼˜é›…é€€å‡ºè€Œä¸æ˜¯å¼ºåˆ¶ç»ˆæ­¢
   - æ£€æŸ¥ data/ ç›®å½•ä¸­çš„éƒ¨åˆ†æ–‡ä»¶
   
4. å¿«é€Ÿæµ‹è¯•ï¼š
   python -c "from utils.github_client import GitHubClient; gc = GitHubClient.create_instance(True); print(gc.get_token_status())"
    """)


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸ”§ KEY SCANNER DIAGNOSTIC TOOL")
    print("="*60)
    print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. æ£€æŸ¥Tokené…ç½®
    token_status = check_token_files()
    
    # 2. æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_files = check_data_files()
    
    # 3. æ£€æŸ¥æŸ¥è¯¢æ–‡ä»¶
    check_queries_file()
    
    # 4. æµ‹è¯•Tokenç®¡ç†å™¨
    manager_ok = test_token_manager()
    
    # 5. æä¾›ä¿®å¤å»ºè®®
    suggest_fixes()
    
    # 6. æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“‹ DIAGNOSIS SUMMARY")
    print("="*60)
    
    issues = []
    
    if token_status['file_tokens'] == 0 and token_status['env_tokens'] == 0:
        issues.append("No tokens configured")
    
    if not data_files:
        issues.append("No data files found")
    
    if not manager_ok:
        issues.append("Token Manager initialization failed")
    
    if issues:
        print("âŒ Issues found:")
        for issue in issues:
            print(f"   - {issue}")
    else:
        print("âœ… Everything looks good!")
    
    print("\nğŸ’¡ Next steps:")
    print("1. Fix any issues identified above")
    print("2. Run the improved scanner: python app/api_key_scanner_improved.py")
    print("3. Or use the unified launcher: ./unified_launcher.sh (Linux/Mac) or unified_launcher.bat (Windows)")


if __name__ == "__main__":
    main()